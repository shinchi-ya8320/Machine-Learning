{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "handled-netscape",
   "metadata": {},
   "source": [
    "モデルのチューニングについて"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "manual-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "#共通前処理\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#必要ライブラリのインポート\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import japanize_matplotlib\n",
    "\n",
    "#データフレーム表示用関数\n",
    "from IPython.display import display\n",
    "\n",
    "#表示オプションの調整\n",
    "\n",
    "#浮動小数点の表示\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "#データフレームのすべての項目を表示する\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#グラフのフォント\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "#乱数\n",
    "random_seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "precious-convenience",
   "metadata": {},
   "outputs": [],
   "source": [
    "#データの読み込み\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "#入力データx, 正解データyの作成\n",
    "x = cancer.data\n",
    "y = cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "surprising-scroll",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "(512, 30)\n",
      "(57, 30)\n"
     ]
    }
   ],
   "source": [
    "#上で読み込んだデータの分割\n",
    "\n",
    "#分割用のパラメータ。訓練データ90%,検証データ10%の比率で分割する。\n",
    "#test_size=0.1は訓練データ10%の意味\n",
    "test_size = 0.1\n",
    "\n",
    "#データ分割.訓練データと検証データ\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "                                                   test_size=test_size, random_state=random_seed,stratify=y)\n",
    "\n",
    "#分割後のサイズ確認\n",
    "print(x.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "#出力で分割されていることを確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "indoor-junction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#上で作成したデータをもとに複数のアルゴリズムリストを作成する\n",
    "#複数のアルゴリズムを作成し、制度を比較する\n",
    "#結果が同じになるようにrandom_stateは同じにする\n",
    "\n",
    "#線形回帰\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algorithm1 = LogisticRegression(random_state=random_seed)\n",
    "\n",
    "#サポートベクターマシン\n",
    "from sklearn.svm import SVC\n",
    "algorithm2 = SVC(kernel='rbf', random_state=random_seed)\n",
    "\n",
    "#決定木\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "algorithm3 = DecisionTreeClassifier(random_state=random_seed)\n",
    "\n",
    "#ランダムフォレスト\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "algorithm4 = RandomForestClassifier(random_state=random_seed)\n",
    "\n",
    "#XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "algorithm5 = XGBClassifier(random_state=random_seed)\n",
    "\n",
    "#アルゴリズムのリスト作成\n",
    "algorithms = [algorithm1, algorithm2, algorithm3, algorithm4, algorithm5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "composed-offer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9474 LogisticRegression\n",
      "score: 0.8947 SVC\n",
      "score: 0.9474 DecisionTreeClassifier\n",
      "score: 0.9298 RandomForestClassifier\n",
      "[12:07:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "score: 0.9825 XGBClassifier\n"
     ]
    }
   ],
   "source": [
    "#for文を実行して、アルゴリズムのリストを次々に実行する\n",
    "for algorithm in algorithms:\n",
    "    \n",
    "    #訓練データで学習\n",
    "    algorithm.fit(x_train, y_train)\n",
    "    \n",
    "    #検証データで精度を調べる\n",
    "    score = algorithm.score(x_test, y_test)\n",
    "    \n",
    "    #アルゴリズム名取得。__class__.__name__はおまじない\n",
    "    name = algorithm.__class__.__name__\n",
    "    \n",
    "    #精度とアルゴリズムを表示する\n",
    "    print(f'score: {score:.4f} {name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-plant",
   "metadata": {},
   "source": [
    "ハイパーパラメータの最適化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "photographic-position",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(random_state=123)\n"
     ]
    }
   ],
   "source": [
    "#SVCのデフォルトパラメータの確認\n",
    "algorithm = SVC(kernel='rbf', random_state=random_seed)\n",
    "print(algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "affected-championship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.6316 gamma:1\n",
      "score: 0.6316 gamma:0.1\n",
      "score: 0.6316 gamma:0.01\n",
      "score: 0.9474 gamma:0.001\n",
      "score: 0.9474 gamma:0.0001\n",
      "score: 0.9474 gamma:1e-05\n"
     ]
    }
   ],
   "source": [
    "#gamma値の最適化\n",
    "algorithm = SVC(kernel='rbf', random_state=random_seed)\n",
    "gammas = [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "\n",
    "for gamma in gammas:\n",
    "    algorithm.gamma = gamma\n",
    "    algorithm.fit(x_train, y_train)\n",
    "    score = algorithm.score(x_test, y_test)\n",
    "    print(f'score: {score:.4f} gamma:{gamma}')\n",
    "    \n",
    "#for文での出力結果でガンマ値を0.001を採用する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "powerful-tulsa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9474 C: 1\n",
      "score: 0.9298 C: 10\n",
      "score: 0.9298 C: 100\n",
      "score: 0.9298 C: 1000\n",
      "score: 0.9298 C: 10000\n"
     ]
    }
   ],
   "source": [
    "#Cの最適化\n",
    "#gammaについては上で出した0.001をつかう\n",
    "\n",
    "Cs = [1, 10, 100, 1000, 10000]\n",
    "\n",
    "for C in Cs:\n",
    "    algorithm = SVC(kernel='rbf', gamma=0.001, C = C, random_state=random_seed)\n",
    "    algorithm.fit(x_train, y_train)\n",
    "    score = algorithm.score(x_test, y_test)\n",
    "    print(f'score: {score:.4f} C: {C}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-universal",
   "metadata": {},
   "source": [
    "交差検定法について"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "duplicate-plant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均スコア: 0.9141 個別スコア: [0.8889 0.9181 0.9353]\n"
     ]
    }
   ],
   "source": [
    "#特定のアルゴリズムで交差検定法を実施\n",
    "\n",
    "#アルゴリズム\n",
    "algorithm = SVC(kernel='rbf', random_state=random_seed,gamma=0.001, C=1)\n",
    "\n",
    "#分割時に正解データの分布が偏らないようにstratifiedkfoldを実施\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "stratifiedKfold = StratifiedKFold(n_splits=3)\n",
    "\n",
    "#交差検定法の実施\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(algorithm, x_train, y_train, cv=stratifiedKfold)\n",
    "\n",
    "#平均値の計算\n",
    "mean = scores.mean()\n",
    "\n",
    "#結果\n",
    "print(f'平均スコア: {mean:.4f} 個別スコア: {scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "satisfied-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    "#候補アルゴリズムのリスト作成\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algorithm1 = LogisticRegression(random_state=random_seed)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "algorithm2 = SVC(kernel='rbf', random_state=random_seed, gamma=0.001, C=1)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "algorithm3 = DecisionTreeClassifier(random_state=random_seed)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "algorithm4 =RandomForestClassifier(random_state=random_seed)\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "algorithm5 = XGBClassifier(random_state=random_seed)\n",
    "\n",
    "\n",
    "algorithms = [algorithm1, algorithm2, algorithm3, algorithm4, algorithm5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "controlling-romance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均スコア: 0.9453 個別スコア:[0.9357 0.9474 0.9529] LogisticRegression\n",
      "平均スコア: 0.9141 個別スコア:[0.8889 0.9181 0.9353] SVC\n",
      "平均スコア: 0.9062 個別スコア:[0.8713 0.9415 0.9059] DecisionTreeClassifier\n",
      "平均スコア: 0.9629 個別スコア:[0.9649 0.9591 0.9647] RandomForestClassifier\n",
      "[12:59:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:59:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:59:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "平均スコア: 0.9570 個別スコア:[0.9474 0.9649 0.9588] XGBClassifier\n"
     ]
    }
   ],
   "source": [
    "#交差検定法を用いて複数のアルゴリズムの精度を比較する\n",
    "\n",
    "#分割時に正解データの分布が偏らないようにする\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "stratifiedKfold = StratifiedKFold(n_splits=3)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#交差検定法を実施\n",
    "for algorithm in algorithms:\n",
    "    scores = cross_val_score(algorithm, x_train, y_train, cv=stratifiedKfold)\n",
    "    \n",
    "    score = scores.mean()\n",
    "    name = algorithm.__class__.__name__\n",
    "    print(f'平均スコア: {score:.4f} 個別スコア:{scores} {name}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-henry",
   "metadata": {},
   "source": [
    "グリッドリサーチについて"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "operating-sustainability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1000, gamma=1e-05, random_state=123)\n"
     ]
    }
   ],
   "source": [
    "#グリッドリサーチに交差検定法を組み合わせて最適なパラメータを探す\n",
    "\n",
    "params = {\n",
    "    'C':[1, 10, 100, 1000, 10000],\n",
    "    'gamma':[1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "}\n",
    "\n",
    "algorithm =SVC(random_state=random_seed)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "stratifiedKfold = StratifiedKFold(n_splits=3)\n",
    "\n",
    "#グリッドリサーチの実施\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(algorithm, params, cv=stratifiedKfold)\n",
    "gs.fit(x_train, y_train)\n",
    "\n",
    "#ベストなモデルを取得して検証データの分類\n",
    "best = gs.best_estimator_\n",
    "best_pred = best.predict(x_test)\n",
    "print(best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "furnished-hindu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "スコア: 0.9825\n",
      "\n",
      "混同行列\n",
      "[[20  1]\n",
      " [ 0 36]]\n"
     ]
    }
   ],
   "source": [
    "#上で作ったモデルの精度を確認する\n",
    "score = best.score(x_test, y_test)\n",
    "print(f'スコア: {score:.4f}')\n",
    "\n",
    "#混同行列を出力\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#空白\n",
    "print()\n",
    "print('混同行列')\n",
    "print(confusion_matrix(y_test, best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-silicon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-train",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-boston",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-labor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-garage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-appearance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-cooperation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-romantic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-participant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-petite",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-boston",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
